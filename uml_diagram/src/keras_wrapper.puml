@startuml

title Keras - Decorator
    

+abstract class Wrapper extends Layer{
    # layer: Layer
    
}

+class Layer{
    # trainable: boolean
    # name: String
    # dynamic: boolean
    # losses: list[Tensor]
    +build(input_shape:TensorShape):void
    + call(inputs:list[Tensor], *args, **kwargs): Tensor
    + compute_output_shape(input_shape:tuple): tuple
    + compute_mask(inputs:Tensor,mask:Tensor): Tensor
}

+class TimeDistributed extends Wrapper{

    # get_shape_tuple(init_tuple:tuple[],tensor:Tensor,start_idx:int,int_shape:TensorShape): tuple
    # remove_timesteps(dims:tuple[int]): tuple
}
+class Dense extends Layer {
    +build(input_shape:list[int]): void
    +call(inputs:list[Tensor])
    +units: int
    +use_bias: boolean
    +supports_masking: boolean
}

+class RNN extends Layer {
    +build(input_shape:list[int])
    +call(inputs:list[Tensor], mask:list[Tensor], training:boolean, initial_state:Sequence, constants:list[Tensor])
    +stateful: boolean
}

+abstract class Conv extends Layer {
    +build(input_shape:list[int])
    +call(inputs:list[Tensor])
    +filters: int
    +kernel_size: tuple[int]
    +use_bias: boolean
    +data_format: String
}
+class Conv1D extends Conv{
    
}
+class Conv2D extends Conv{

}
+class Conv3D extends Conv{
    
}
+class Bidirectional extends Wrapper{
    + backward_layer: Layer
    + forward_layer: Layer
    + go_backwards: boolean
    + merge_mode: String
    # recreate_layer_from_config(layer:Layer,go_backwards:boolean):Layer
    + call(inputs:list[Tensor],training:boolean,mask:list[Tensor],initial_state:Sequence, constants:list[Tensor]): Tensor|tuple|list
}
+class cilent{

}
cilent -down-> Layer
Layer <-left- Wrapper
@enduml
